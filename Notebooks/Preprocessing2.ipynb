{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d966fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import skimage.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b19bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/speech-emotion-recognition-ravdess-data/Actor_16',\n",
       " '03-01-05-01-02-01-16.wav')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.split('data/speech-emotion-recognition-ravdess-data/Actor_16/03-01-05-01-02-01-16.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0a87777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(file_path):\n",
    "    path_list = file_path.split('/')\n",
    "    img_path = path_list[-1]\n",
    "    \n",
    "     # settings\n",
    "    hop_length = 512 # number of samples per time-step in spectrogram\n",
    "    n_mels = 128 # number of bins in spectrogram. Height of image\n",
    "    time_steps = 384 # number of time-steps. Width of image\n",
    "\n",
    "    # load audio. Using example from librosa\n",
    "    y, sr = librosa.load(file_path, sr=22050)\n",
    "    y = y[20000:60000]\n",
    "    y = np.resize(y, (256, 256))\n",
    "    out = 'data/images2/' + img_path[:-4] + '.npy'\n",
    "    \n",
    "    # Save as numpy array\n",
    "    np.save(out, y)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2165429",
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_emotions = {'01':'neutral', '02':'calm', '03':'happy', '04':'sad',\\\n",
    "                   '05':'angry', '06':'fear', '07':'disgust','08':'surprise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ff4553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Images Written\n"
     ]
    }
   ],
   "source": [
    "processed_data = []\n",
    "# Folder path of the data \n",
    "data_path = 'data/speech-emotion-recognition-ravdess-data/'\n",
    "\n",
    "# Extracting Label of audio clip from the file name based on the name of the dataset. \n",
    "for root, dirs, files in os.walk(data_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.DS_Store'):\n",
    "            continue\n",
    "        file_path = os.path.join(root, file)\n",
    "        # Split the file name based on dataset\n",
    "        file_breakdown = file.split('-')\n",
    "        if file_breakdown[3] == '01' and file_breakdown[5] == '01':\n",
    "            emotion = ravdess_emotions[file_breakdown[2]]\n",
    "            emotion_id = int(file_breakdown[2])\n",
    "            statement = int(file_breakdown[4])\n",
    "            actor = int(file_breakdown[6][:-4])\n",
    "\n",
    "            img_path = get_image_path(file_path)\n",
    "            #print(emotion)\n",
    "            processed_data.append([file_path, actor, emotion, emotion_id, statement, img_path])\n",
    "print(\"All Images Written\")\n",
    "# Compute Recipe Outputs: \n",
    "speech_data_processed_df = pd.DataFrame(processed_data, columns=['file_name','actor','emotions','emotion_id','statement','image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c871f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>actor</th>\n",
       "      <th>emotions</th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>statement</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data/images2/03-01-01-01-01-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>calm</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data/images2/03-01-02-01-01-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>happy</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data/images2/03-01-03-01-01-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>data/images2/03-01-04-01-01-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>angry</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>data/images2/03-01-05-01-01-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>data/images2/03-01-06-01-01-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>disgust</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>data/images2/03-01-07-01-01-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>surprise</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>data/images2/03-01-08-01-01-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>data/images2/03-01-01-01-02-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>calm</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>data/images2/03-01-02-01-02-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>happy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>data/images2/03-01-03-01-02-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>data/images2/03-01-04-01-02-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>angry</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>data/images2/03-01-05-01-02-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>data/images2/03-01-06-01-02-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>disgust</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>data/images2/03-01-07-01-02-01-01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data/speech-emotion-recognition-ravdess-data/A...</td>\n",
       "      <td>1</td>\n",
       "      <td>surprise</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>data/images2/03-01-08-01-02-01-01.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file_name  actor  emotions  \\\n",
       "0   data/speech-emotion-recognition-ravdess-data/A...      1   neutral   \n",
       "1   data/speech-emotion-recognition-ravdess-data/A...      1      calm   \n",
       "2   data/speech-emotion-recognition-ravdess-data/A...      1     happy   \n",
       "3   data/speech-emotion-recognition-ravdess-data/A...      1       sad   \n",
       "4   data/speech-emotion-recognition-ravdess-data/A...      1     angry   \n",
       "5   data/speech-emotion-recognition-ravdess-data/A...      1      fear   \n",
       "6   data/speech-emotion-recognition-ravdess-data/A...      1   disgust   \n",
       "7   data/speech-emotion-recognition-ravdess-data/A...      1  surprise   \n",
       "8   data/speech-emotion-recognition-ravdess-data/A...      1   neutral   \n",
       "9   data/speech-emotion-recognition-ravdess-data/A...      1      calm   \n",
       "10  data/speech-emotion-recognition-ravdess-data/A...      1     happy   \n",
       "11  data/speech-emotion-recognition-ravdess-data/A...      1       sad   \n",
       "12  data/speech-emotion-recognition-ravdess-data/A...      1     angry   \n",
       "13  data/speech-emotion-recognition-ravdess-data/A...      1      fear   \n",
       "14  data/speech-emotion-recognition-ravdess-data/A...      1   disgust   \n",
       "15  data/speech-emotion-recognition-ravdess-data/A...      1  surprise   \n",
       "\n",
       "    emotion_id  statement                             image_path  \n",
       "0            1          1  data/images2/03-01-01-01-01-01-01.npy  \n",
       "1            2          1  data/images2/03-01-02-01-01-01-01.npy  \n",
       "2            3          1  data/images2/03-01-03-01-01-01-01.npy  \n",
       "3            4          1  data/images2/03-01-04-01-01-01-01.npy  \n",
       "4            5          1  data/images2/03-01-05-01-01-01-01.npy  \n",
       "5            6          1  data/images2/03-01-06-01-01-01-01.npy  \n",
       "6            7          1  data/images2/03-01-07-01-01-01-01.npy  \n",
       "7            8          1  data/images2/03-01-08-01-01-01-01.npy  \n",
       "8            1          2  data/images2/03-01-01-01-02-01-01.npy  \n",
       "9            2          2  data/images2/03-01-02-01-02-01-01.npy  \n",
       "10           3          2  data/images2/03-01-03-01-02-01-01.npy  \n",
       "11           4          2  data/images2/03-01-04-01-02-01-01.npy  \n",
       "12           5          2  data/images2/03-01-05-01-02-01-01.npy  \n",
       "13           6          2  data/images2/03-01-06-01-02-01-01.npy  \n",
       "14           7          2  data/images2/03-01-07-01-02-01-01.npy  \n",
       "15           8          2  data/images2/03-01-08-01-02-01-01.npy  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_data_processed_df = speech_data_processed_df.sort_values(by=['actor','statement','emotion_id'], ignore_index=True)\n",
    "speech_data_processed_df.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aabd6827",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_data_processed_df.to_csv('data/RAVDESS_processed_dataset_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ba0c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00000000e+000, 3.31023983e-322, 0.00000000e+000,\n",
       "         0.00000000e+000, 8.48798316e-314],\n",
       "        [1.16095484e-028, 7.47870832e+247, 4.82410605e+228,\n",
       "         1.01392767e-076, 9.80422498e+252],\n",
       "        [9.98586082e-077, 1.25229219e+219, 1.46412291e-028,\n",
       "         5.49497060e-096, 5.07507647e+246]],\n",
       "\n",
       "       [[4.10067162e+223, 6.01347002e-154, 6.01347002e-154,\n",
       "         1.46461594e-028, 5.49497762e-096],\n",
       "        [1.23368276e+184, 9.98586082e-077, 2.16222309e+190,\n",
       "         4.74694520e-038, 1.75471250e+243],\n",
       "        [1.04919172e-153, 9.78750380e+199, 6.97843734e+252,\n",
       "         2.65698126e-312, 0.00000000e+000]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty((2, 3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1be4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
